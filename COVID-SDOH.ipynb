{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "See requirements.txt for versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import logit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, callbacks, utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "tf.config.run_functions_eagerly(True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Workspace specific, we worked inside of the AllofUs Research Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "output = 'lNH'\n",
    "dataset = df[[output, 'AGE', 'RACE', 'GENDER', 'marital', 'income', 'employ', 'edu']].copy()\n",
    "train, rem = train_test_split(dataset, train_size=.7, random_state=42)\n",
    "valid, test = train_test_split(dataset, train_size=.5, random_state=42)\n",
    "features = ['RACE', 'GENDER', 'marital', 'income', 'employ', 'edu', 'AGE']\n",
    "output = dataset.loc[:, ~dataset.columns.isin(features)].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data, catcols):    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for c in catcols:\n",
    "        num_unique_values = int(data[c].nunique())\n",
    "        embed_dim = int(min(np.ceil(num_unique_values / 2), 50))\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        out = layers.Embedding(num_unique_values + 1, embed_dim, name=c)(inp)\n",
    "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
    "        inputs.append(inp)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    x = layers.Concatenate()(outputs)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    y = layers.Dense(len(output), activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = create_model(train, features)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.01, patience=50, mode='max', restore_best_weights=True)\n",
    "\n",
    "mlabel = len(output) > 1\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[tf.keras.metrics.AUC(multi_label=mlabel)])\n",
    "\n",
    "history = model.fit(x=[train.loc[:, f].values for f in features], \n",
    "                    y=train[output].values, \n",
    "                    validation_data=([valid.loc[:, f].values for f in features], valid[output].values),\n",
    "                    epochs=1000, \n",
    "                    batch_size=128,\n",
    "                    verbose=2,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=[test.loc[:, f].values for f in features], \n",
    "               y=test[output].values,\n",
    "               verbose = 2,\n",
    "               callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact Score Measurement\n",
    "- First, a saved model is loaded and used to make predictions the results of which are passed through a logit function. \n",
    "- Next, reference values for each category is chosen (we used the most frequent value but this is not required)\n",
    "- Then, the impact score can be calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains encoding information for the purposes of calculating impact scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr = pd.DataFrame(data=[[3, 0, 2, 1, 2, 2, 4]], \n",
    "                  columns=['RACE', 'GENDER', 'marital', 'income', 'employ', 'edu', 'AGE'])\n",
    "\n",
    "race = {0: 'Black or African American', 1: 'Other', 2: 'Skip', 3: 'White'}\n",
    "gender = {0: 'Female', 1: 'Male', 2: 'Unknown'}\n",
    "marital = {0: '0', 1: 'DSW', 2: 'MLWP', 3: 'NM'}\n",
    "income = {0: '0', 1: '100-150K', 2: '150K+', 3: '25-75K', 4: '75-100K', 5: '<25K'}\n",
    "employ = {0: '0', 1: 'Employed', 2: 'Unemployed'}\n",
    "edu = {0: '0', 1: '<HS', 2: 'College+', 3: 'HS/GED', 4: 'someCollege'}\n",
    "age = {0: 66, 1: 67, 2: 68, 3: 69, 4: 70,\n",
    "       5: 71, 6: 72, 7: 73, 8: 74, 9: 75,\n",
    "       10: 76, 11: 77, 12: 78, 13: 79,\n",
    "       14: 80, 15: 81, 16: 82, 17: 83,\n",
    "       18: 84, 19: 85, 20: 86, 21: 87,\n",
    "       22: 88, 23: 89, 24: 90}\n",
    "\n",
    "def translate(feat, variable):\n",
    "    if feat is 'RACE':\n",
    "        return race.get(variable)\n",
    "    elif feat is 'GENDER':\n",
    "        return gender.get(variable)\n",
    "    elif feat is 'marital':\n",
    "        return marital.get(variable)\n",
    "    elif feat is 'income':\n",
    "        return income.get(variable)\n",
    "    elif feat is 'employ':\n",
    "        return employ.get(variable)\n",
    "    elif feat is 'edu':\n",
    "        return edu.get(variable)\n",
    "    elif feat is 'AGE':\n",
    "        return age.get(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_file)\n",
    "lipred = logit(model.predict(x=[dataset.loc[:, f].values for f in features],\n",
    "                     verbose = 0))\n",
    "\n",
    "mIndex = 0\n",
    "templist = lipred.tolist()\n",
    "mlipred = []\n",
    "for element in templist:\n",
    "    mlipred.append(element[mIndex])\n",
    "impactdf = dataset.copy()\n",
    "impactdf['lipred'] = mlipred\n",
    "impactdf['tAGE'] = 4\n",
    "impactdf['tRACE'] = 3\n",
    "impactdf['tGENDER'] = 0\n",
    "impactdf['tmarital'] = 2\n",
    "impactdf['tincome'] = 1\n",
    "impactdf['temploy'] = 2\n",
    "impactdf['tedu'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impactscore(fxi, fxr, xi, xr, feat):\n",
    "    if abs(xi-xr) is 0:\n",
    "        return None\n",
    "    elif feat is 'AGE':\n",
    "        impact = (fxi-fxr)/(xi-xr)\n",
    "        return impact\n",
    "    else:\n",
    "        impact = (fxi-fxr)\n",
    "        return impact\n",
    "    \n",
    "opdf = pd.DataFrame(columns = ['label', 'impactscore'])    \n",
    "for feat in tqdm(features):\n",
    "    xfeatures = ['t'+xfeat if xfeat is feat else xfeat for xfeat in features]\n",
    "    lrpred = logit(model.predict(x=[impactdf.loc[:, f].values for f in xfeatures],\n",
    "                   verbose = 0))\n",
    "    temppred = lrpred.tolist()\n",
    "    mlrpred = []\n",
    "    for element in temppred:\n",
    "        mlrpred.append(element[mIndex])\n",
    "    impactdf['lrpred'] = mlrpred\n",
    "    feat_list = impactdf[feat].unique().tolist()\n",
    "    label = feat + '_impactscore_'\n",
    "    impactdf[label] = [impactscore(row[0], row[1], row[2], row[3], feat) for row in zip(impactdf['lipred'], impactdf['lrpred'], impactdf[feat], impactdf['t'+feat])]\n",
    "    for variable in feat_list:\n",
    "        tempdf = impactdf.loc[impactdf[feat] == variable]\n",
    "        op = tempdf[label].mean()\n",
    "        opdf.loc[len(opdf.index)] = [feat + '_' + str(translate(feat, variable)), op]\n",
    "    \n",
    "opdf.style.hide_index()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
